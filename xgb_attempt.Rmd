---
title: "XGBoost Comparison"
author: "Andrew vanderWilden"
date: "6/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}
library(tidyverse)
library(xgboost)
library(Metrics)

set.seed(5353)

df = read.table("auto-ins.tsv", header = TRUE)
```

```{r}
df <- df %>%
  mutate(reg.grp = case_when(
      region == "Highlands" ~ "HLPC",
      region == "Lakeview" ~ "HLPC",
      region == "Piety Corner" ~ "HLPC",
      region == "Bleachery" ~ "BSBW",
      region == "Banks Square" ~ "BSBW",
      region == "Warrendale" ~ "BSBW",
      region == "The Lanes" ~ "HLPC",
      region == "The Chemistry" ~ "Chem",
      TRUE ~ "Other"))

df$reg.grp <- factor(df$reg.grp,
                    levels = c("HLPC", "BSBW", "Chem"))

df <- df %>%
    mutate(use.colps = case_when(
      vehicle.use == "Business" ~ "B&C",
      vehicle.use == "Commute" ~ "B&C",
      vehicle.use == "Private" ~ "Prv",
      TRUE ~ "Other"))

df$use.colps <- factor(df$use.colps,
                       levels = c("Prv", "B&C"))

df$v.bod <- fct_collapse(df$vehicle.body,
                           FML = c("Minibus", "Station Wagon"),
                           MED = c("Hatchback", "SUV", "Sedan"),
                           HST = c("Truck", "Panel Van", "Roadster"))

bks <- c(16, 20, 24, 30, 40, 50, 60, 76)


lbs <- c("17-20", "21-24", "25-30", "31-40", 
         "41-50", "51-60", "61-75")

df$age.cat <- cut(df$age, breaks = bks, labels = lbs)
  
```



```{r}
df1 <- df %>%
  select(claims,
         gender,
         age.cat,
         use.colps,
         reg.grp,
         v.bod,
         exposure)

head(df1)
```



```{r}
Gender <- model.matrix(~gender-1, df1)
Age <- model.matrix(~age.cat-1, df1)
Use <- model.matrix(~use.colps-1, df1)
Reg <- model.matrix(~reg.grp-1, df1)
Body <- model.matrix(~v.bod-1, df1)


df_num <- cbind(Gender, Age, Use, Reg, Body)

df_matrix <- data.matrix(df_num)

df_label <- as_vector(df1$claims)
df_exposure <- as_vector(df1$exposure)

train_idx <- sample(10000,7000, replace = FALSE)

train_data <- df_matrix[train_idx,]
train_label <- df_label[train_idx]
train_exposure <- df_exposure[train_idx]

test_data <- df_matrix[-train_idx,]
test_label <- df_label[-train_idx]
test_exposure <- df_exposure[-train_idx]

dtrain <- xgb.DMatrix(data = train_data, label = train_label)
dtest <- xgb.DMatrix(data = test_data, label = test_label)

setinfo(dtrain, "base_margin", log(train_exposure)) # For offset
setinfo(dtest, "base_margin", log(test_exposure))

```

```{r}
fin_mod <- glm(claims~gender + age.cat + use.colps + reg.grp + v.bod + gender:age.cat, data = df1[train_idx,], family = poisson(link = "log"),offset = log(exposure))


asdf <- fin_mod$coefficients

fdsa <- tibble(Coefficient = names(asdf), Value = asdf)

knitr::kable(asdf)

```

```{r}
model <- xgboost(data = dtrain,
                 objective = "count:poisson",
                 max.depth = 3,
                 early_stopping_rounds = 4,
                 print_every_n = 10,
                 nrounds = 500,
                 min_child_weight = 1,
                 gamma = 1)
```
```{r}
model2 <- xgboost(data = dtrain,
                 objective = "count:poisson",
                 max.depth = 2,
                 early_stopping_rounds = 4,
                 print_every_n = 10,
                 nrounds = 500,
                 min_child_weight = 1,
                 gamma = 1)
```

```{r}
model3 <- xgboost(data = dtrain,
                 objective = "count:poisson",
                 max.depth = 2,
                 #early_stopping_rounds = 4,
                 print_every_n = 10,
                 nrounds = 500,
                 min_child_weight = 1,
                 gamma = 1)
```


```{r}
mat <- xgb.importance(names(df_matrix),
                      model = model)

xgb.ggplot.importance(mat)
```


```{r}

xgb_pred <- predict(model, dtest)
xgb2_pred <- predict(model2, dtest)
xgb3_pred <- predict(model3, dtest)
glm_pred <- predict(fin_mod, df1[-train_idx,], type = "response")

xgb2_o_pred <- predict(model2, dtrain)
glm_o_pred <- predict(fin_mod, df1[train_idx,], type = "response")
xgb3_o_pred <- predict(model3, dtrain)
```

```{r}
msep_fit <- function(x,y) {
  ans <- mean((y-x)^2)
  return(ans)
}
```

```{r}
msep_fit(xgb_pred, test_label)
```


```{r}
msep_fit(xgb2_pred, test_label)
```

```{r}
msep_fit(xgb3_pred, test_label)
```


```{r}
msep_fit(glm_pred, test_label)
```

```{r}
msep_fit(xgb2_o_pred, train_label)
```

```{r}
msep_fit(xgb3_o_pred, train_label)
```


```{r}
msep_fit(glm_o_pred, train_label)
```


